---
title: 'Reading files: beyond the basics'
author: "Patrick Mathias"
output: powerpoint_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(janitor)
library(fs)
```

## Base reading functions

Problems with `read.csv()` and similar base functions:

- Parsing strings: `stringsAsFactors = TRUE`
  - Big problem: converting factor back to numeric
- Consider explicitly defining data types
  
## Exercise 1: Refresher on reading in files

Refresher on reading in files using `read.table` functions

## General issues with base reading functions

- they are slow for reading large files (slow compared to?)
- the automatic conversion of strings to factors by default can be annoying to turn off
- output with row names by default can be annoying to turn off

## Improvements with the *readr* package

- Faster (~10x)
- Strings are preserved by default
- Writing does not default to include row numbers/names
- Similar function names to base: `read_csv()`
- Writing files to csv: `write_excel_csv()`

## Syntax and arguments

```{r, eval = FALSE}
# purely a dummy example, not executable!
imaginary_data_frame <- read_csv(
  "imaginary_file.csv",
  col_types = cols(
    x = col_integer(),
    y = col_character(),
    z = col_datetime()
  )
)
```

## Exercise 2

Use readr to read in files and explicitly define column types

### Writing files

- readr has writing funtions as well
- `write_excel_csv` writes csvs that play nice with Excel

## Dealing with Excel files (gracefully)

- [readxl package](http://readxl.tidyverse.org/)
- no external dependencies like xlsx package
- Syntax: `read_excel("file_name.xlsx")`
- Can pull in specific worksheets or subsets of data:
  - `sheet = "worksheet_name"` argument
  - `read_excel("file_name.xlsx", range = "B1:D6")`
  - `read_excel("file_name.xlsx, range = cell_cols("A:F")`
  
- [tidyxl package](https://cran.r-project.org/web/packages/tidyxl/vignettes/tidyxl.html) for more complex Excel operations

## Exercise 3

Read an Excel file or subset using readxl

## Exercise 3

```{r, echo = TRUE, eval = FALSE}
library(readxl)
readxl_load <- read_excel("data/orders_data_set.xlsx")
glimpse(readxl_load)
```

## Exercise 3

```{r, echo = FALSE}
library(readxl)
readxl_load <- read_excel(here("data/orders_data_set.xlsx"))
glimpse(readxl_load)
```

## Importing dirty data with janitor

[janitor package](https://github.com/sfirke/janitor)

- `clean_names()` will reformat column names to conform to the tidyverse style guide: spaces are replaced with underscores & uppercase letters are converted to lowercase
- empty rows and columns are removed with `remove_empty_rows()` or `remove_empty_columns()`
- `tabyl(variable)` will tabulate into a data frame based on 1-3 variables supplied to it

## Clean names example

```{r janitor_code, eval = FALSE}
# install.packages("janitor", dependencies = TRUE) # uncomment to install if needed
library(janitor)
readxl_load_cleaned <- readxl_load %>%
  clean_names()
head(readxl_load_cleaned)
```

## Clean names example

```{r janitor, echo = FALSE}
# install.packages("janitor", dependencies = TRUE) # uncomment to install if needed
library(janitor)
readxl_load_cleaned <- readxl_load %>%
  clean_names()
head(readxl_load_cleaned)
```

## Tabluation example

```{r tabyl_code, eval = FALSE}
readxl_load_cleaned %>% tabyl(order_class_c_descr)
```

## Tabluation example

```{r tabyl, echo = FALSE}
readxl_load_cleaned %>% tabyl(order_class_c_descr)
```

## Why use iteration when reading files?

Scenario:

- you have 12 months of data in 12 different files
- you want to create a single data frame that includes the data
- files are named systematically and have the same structure & column names

Perfect scenario to iterate through a list

## Purrr package and map functions

- [purrr package](https://purrr.tidyverse.org) has a variety of `map()` functions
- `map()` functions
  - take a vector as an input
  - apply a function to elements of the vector
  - return a vector of identical length to the input vector

## map() example

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
df %>%
  map_dbl(mean)
```

## Prerequisites to use map() to read files

- the underlying file structure must be the same: for spreadsheet-like data, columns must be in the same positions in each with consistent data types
- the files must have the same file extension
- if there are multiple different file types (with different data structures) mixed in one directory, the files must organized and named in a way to associate like data sets with like

## Reading class data into one large data frame

```{r, eval = FALSE}
all_samples <- dir_ls("data", glob = "*_s.csv") %>%
  map_dfr(read_csv) %>%
  clean_names()
summary(all_samples)
```

## Reading class data into one large data frame

```{r, echo = FALSE, message = FALSE}
all_samples <- dir_ls(here("data"), glob = "*_s.csv") %>%
  map_dfr(read_csv) %>%
  clean_names()
summary(all_samples)
```

## Word of warning

Don't automate a broken process!

Always thoroughly vet your iteration code

## Summary

- The base R functions for reading files `read.delim()`, `read.csv()`, etc. are useful tools but it is important to recognize how they handle strings (and the dangers in automatic conversion to factors)
- readr functions such as `read_delim()` or `read_csv()` are faster than base R functions and do not automatically convert strings to factors
- The readxl function `read_excel()` reads Excel files and offers functionality in specifying worksheets or subsets of the spreadsheet

## Summary

- The janitor package can help with cleaning up irregularly structured input files
- The purrr package has useful tools for iterating that can be very powerful when coupled with file reading functions
